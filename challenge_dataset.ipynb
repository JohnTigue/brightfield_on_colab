{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "challenge_dataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQQb1m85EkvC",
        "colab_type": "text"
      },
      "source": [
        "# BARC dataset\n",
        "\n",
        "In many ways this BARC dataset is much like The Allen's [BigNeuron project](https://alleninstitute.org/what-we-do/brain-science/news-press/articles/bigneuron-project-launched-advance-3d-reconstructions-neurons) of a few years ago. \n",
        "\n",
        "Here though there is only one type of data: brightfield imaging of biocytin stained neurons. Each neuron's image stack on the order of 10 gigabytes of data.\n",
        "\n",
        "## Access info\n",
        "The challenge dataset is hosted on Wasabi Cloud Storage, which mimics the APIs of AWS S3 so all the regular ways of accessing data on S3 can be used to access the data\n",
        "\n",
        "- Service endpoint address: s3.wasabisys.com\n",
        "- Access Key Id: 2G7POM6IZKJ3KLHSC4JB\n",
        "- Secret Access Key: 0oHD5BXPim7fR1n7zDXpz4YoB7CHAHAvFgzpuJnt\n",
        "- Storage region: us-west-1\n",
        "- bucket name: brightfield-auto-reconstruction-competition  \n",
        "\n",
        "## Overview of bucket's contents\n",
        "There are two parts to the data\n",
        "1. training data (100+ neurons, with manual SWCs)\n",
        "2. test data (10 neurons, no SWCs)\n",
        "\n",
        "Each neuron is in its own folder off the root of the bucket. So the are over 100 folders with names like `647225829`, `767485082`, and `861519869`.\n",
        "\n",
        "Each neuron's data is in a separate folder. Each folder consists of\n",
        "- the input: a few hundred TIFF image files\n",
        "- the output: one SWC manually traced skeleton file\n",
        "\n",
        "There is one unusual sub-root folder, `TEST_DATA_SET`, which contains the data for the ten neurons used during the challenge's evaluation phase. These ten neuron image stacks *DO NOT* have SWC files.\n",
        "\n",
        "The goal is that some software will read the image stack  and auto reconstruct the SWC, without a human having to manually craft a SWC skeleton file (or at least minimize the human input time).\n",
        "\n",
        "So, the idea is a two phase challenge: first train with answers (SWC files), then submit 10 SWC files the program generates on the ten neurons in `TEST_DATA_SET`. \n",
        "\n",
        "sfirst train a auto reconstruction program using the roughly 100 neurons in the training data set, and check your results against the human traced SWC skeletons that each neuron's image stack comes with. Then for the evaluation phase\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Each image stack has its own image count, seemingly a few hunderd TIFF images each (e.g., 270, 500, 309, etc.). Each stack's images are all the same size but the sizes differ between stacks (e.g. 33MB images, 58MB images, etc.). Seemingly, on the order of 30 to 50 MB per image. \n",
        "\n",
        "One TEST_DATA_SET sample neuron's data is a folder, named `665856925`:\n",
        "- Full of about 280 TIFF images\n",
        "- All files named like:`reconstruction_0_0539044525_639962984-0007.tif` \n",
        "- The only thing that changes is the last four characters in the filename root, after the hyphen.\n",
        "- Each file is about 33 MB in size\n",
        "- One neuron's data is on the order of 10 gigabyte\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kGsnQdpN7Bk",
        "colab_type": "text"
      },
      "source": [
        "# Colab can handle one neuron's data at a time\n",
        "\n",
        "\n",
        "Consider one large neuron, Name/ID of `647225829`. This one has 460 images, each 57.7MB. So, a single neuron's data can be as big as, say, 25 gigabytes. \n",
        "\n",
        "Fortuneately, Google's Colab has that much file system. They give out 50GB file systems. And if you ask for a GPU they actually give you 350GB. (U-Net can use a GPU.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thLxqVkTEeBg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cdfc3359-b0c5-4478-d8e9-a95f2ee681c0"
      },
      "source": [
        "# Get some stats on the file system:\n",
        "!!df -h .\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Filesystem      Size  Used Avail Use% Mounted on',\n",
              " 'overlay          49G   25G   22G  54% /']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMl6yoM8Y8RF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF1wgPGPNjov",
        "colab_type": "text"
      },
      "source": [
        "The default file system on Colab is 50G, but a 360G file system can be requested, simply by configuring the runtime to have a GPU (yup).\n",
        "\n",
        "So, on the default (25G) file system, half the file system is already used by the OS and other pre-installed software. A big neuron's data would consume the remaining 25G. So **probably a good idea to request a GPU** which will also come with ~360G file system.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPPpOhoAZfo4",
        "colab_type": "text"
      },
      "source": [
        "## Overview of the dataset\n",
        "\n",
        "\n",
        "The data is stored on Wasabi Cloud Storage, which mimics the AWS S3 APIs, so AWS's Python client, boto3, can be used to access the data. boto3 comes preinstalled on Colab.\n",
        "\n",
        "Here's Wasabi's how-to doc, [How do I use the AWS SDK for Python (boto3) with Wasabi?\n",
        "](https://wasabi-support.zendesk.com/hc/en-us/articles/115002579891-How-do-I-use-the-AWS-SDK-for-Python-boto3-with-Wasabi-)\n",
        "\n",
        "The goal here is to have a bit of code that complete maps the dataset's file system. All 115 neurons and all their files (names and sizes) programmatically indexed into a convenient data structure with which to build out manifest files for, say, ShuTu or some U-Net reconstructor to process. I.e. this will make it easier for folks to massage the data into whatever tool they decide to run with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akBdiF6snGGo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "37ea1d73-0ffc-4303-ec75-9d27c93a8a21"
      },
      "source": [
        "import boto3\n",
        "\n",
        "s3 = boto3.resource('s3',\n",
        "     endpoint_url = 'https://s3.us-west-1.wasabisys.com',\n",
        "     aws_access_key_id = '2G7POM6IZKJ3KLHSC4JB',\n",
        "     aws_secret_access_key = \"0oHD5BXPim7fR1n7zDXpz4YoB7CHAHAvFgzpuJnt\")  \n",
        "bucket = s3.Bucket('brightfield-auto-reconstruction-competition')\n",
        "\n",
        "result = bucket.meta.client.list_objects(Bucket=bucket.name,\n",
        "                                         Delimiter='/')\n",
        "print( \"total root subfolders = \" + str(sum(1 for _ in result.get('CommonPrefixes') )) + \"\\n\")\n",
        "\n",
        "def sumObjectsForPrefix(a_prefix):\n",
        "  \"sums gigabytes of file system occupied by all objects is a directory)\"\n",
        "  tots = 0\n",
        "  tots = sum(1 for _ in bucket.objects.filter(Prefix = a_prefix)) \n",
        "  return tots\n",
        "\n",
        "# The hundred or so training TIFF stacks, with SWCs                    \n",
        "training_neurons = {}\n",
        "for o in result.get('CommonPrefixes'):\n",
        "  a_prefix = o.get('Prefix')\n",
        "  # 106 lines of random numbers: \n",
        "  #print(a_prefix)\n",
        "  \n",
        "  # Enumerate all files\n",
        "  # print(\"----------------\")\n",
        "  imagestack_bytes = 0\n",
        "  imagestack = []\n",
        "  swc_key = None\n",
        "  for s3_object in bucket.objects.filter(Prefix = a_prefix):\n",
        "    # print(s3_object.key + \"= \" + str(s3_object.size))\n",
        "    if not s3_object.key.endswith(\".swc\"):\n",
        "      if s3_object.key != a_prefix:\n",
        "        # if == it's the directory itself, not a file in it so ignore\n",
        "        imagestack.append(s3_object.key)\n",
        "        imagestack_bytes += s3_object.size\n",
        "    else:\n",
        "      swc_key = s3_object.key\n",
        "  \n",
        "  if a_prefix != \"TEST_DATA_SET/\":\n",
        "    training_neurons[a_prefix] = {\"prefix\": a_prefix, \"swc\": swc_key, \"imagestack\": imagestack, \"size\": imagestack_bytes}\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "print( \"# training neurons: \" + str(len(training_neurons)))    \n",
        "\n",
        "# https://stackoverflow.com/a/49361727\n",
        "def format_bytes(size):\n",
        "    # 2**10 = 1024\n",
        "    power = 2**10\n",
        "    n = 0\n",
        "    power_labels = {0 : '', 1: 'kilo', 2: 'mega', 3: 'giga', 4: 'tera'}\n",
        "    while size > power:\n",
        "        size /= power\n",
        "        n += 1\n",
        "    return size, power_labels[n]+'bytes'\n",
        "  \n",
        "for a_neuron_name in training_neurons:\n",
        "  a_neuron = training_neurons[a_neuron_name]\n",
        "  sizeAndUnit = format_bytes(a_neuron[\"size\"])\n",
        "  print(a_neuron_name + \": \" + str(len(a_neuron[\"imagestack\"])) + \"= \" + '{:02.2f}'.format(sizeAndUnit[0]) + \" \" + sizeAndUnit[1] )\n",
        "    \n",
        "# The ten training TIFF stacks, without SWCs                    \n",
        "testing_neurons = {}\n",
        "    \n",
        "  \n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total root subfolders = 106\n",
            "\n",
            "# training neurons: 105\n",
            "647225829/: 460= 24.74 gigabytes\n",
            "647244741/: 261= 8.00 gigabytes\n",
            "647247980/: 299= 9.15 gigabytes\n",
            "647278927/: 346= 17.49 gigabytes\n",
            "647289876/: 228= 7.01 gigabytes\n",
            "649052017/: 307= 9.42 gigabytes\n",
            "650917845/: 245= 9.98 gigabytes\n",
            "651511374/: 414= 12.72 gigabytes\n",
            "651748297/: 336= 7.02 gigabytes\n",
            "651790667/: 250= 13.42 gigabytes\n",
            "651806289/: 291= 6.05 gigabytes\n",
            "651829339/: 529= 35.29 gigabytes\n",
            "651834134/: 469= 14.44 gigabytes\n",
            "652113069/: 359= 14.56 gigabytes\n",
            "654221379/: 334= 10.27 gigabytes\n",
            "654591451/: 300= 12.18 gigabytes\n",
            "663523681/: 539= 27.28 gigabytes\n",
            "663961066/: 414= 16.82 gigabytes\n",
            "664466860/: 382= 11.73 gigabytes\n",
            "668664690/: 464= 14.33 gigabytes\n",
            "669371214/: 295= 11.97 gigabytes\n",
            "672278613/: 330= 10.12 gigabytes\n",
            "673066511/: 283= 14.52 gigabytes\n",
            "674317065/: 344= 18.39 gigabytes\n",
            "676633030/: 387= 10.65 gigabytes\n",
            "677326176/: 595= 24.10 gigabytes\n",
            "677347027/: 586= 18.04 gigabytes\n",
            "685884456/: 492= 20.07 gigabytes\n",
            "687702530/: 358= 18.06 gigabytes\n",
            "687746742/: 608= 59.87 gigabytes\n",
            "688712523/: 481= 19.56 gigabytes\n",
            "689485972/: 362= 30.10 gigabytes\n",
            "691329423/: 538= 16.54 gigabytes\n",
            "691830341/: 607= 24.69 gigabytes\n",
            "692932326/: 557= 17.16 gigabytes\n",
            "693441787/: 316= 21.09 gigabytes\n",
            "693978543/: 386= 15.71 gigabytes\n",
            "694569649/: 486= 26.10 gigabytes\n",
            "694613686/: 446= 18.11 gigabytes\n",
            "696228200/: 435= 13.40 gigabytes\n",
            "696560235/: 509= 25.68 gigabytes\n",
            "697851947/: 850= 45.67 gigabytes\n",
            "699189400/: 650= 53.79 gigabytes\n",
            "699207642/: 389= 11.94 gigabytes\n",
            "702233284/: 614= 33.21 gigabytes\n",
            "704338365/: 614= 24.93 gigabytes\n",
            "704353262/: 612= 32.80 gigabytes\n",
            "704363712/: 610= 32.87 gigabytes\n",
            "706002308/: 378= 11.58 gigabytes\n",
            "706065773/: 572= 23.14 gigabytes\n",
            "707517873/: 547= 27.56 gigabytes\n",
            "710114253/: 466= 18.90 gigabytes\n",
            "710124691/: 488= 26.17 gigabytes\n",
            "712951287/: 527= 16.15 gigabytes\n",
            "712977942/: 622= 25.18 gigabytes\n",
            "713016653/: 554= 17.01 gigabytes\n",
            "713686035/: 289= 8.87 gigabytes\n",
            "715273626/: 594= 31.81 gigabytes\n",
            "715286106/: 482= 14.80 gigabytes\n",
            "715328776/: 322= 17.23 gigabytes\n",
            "718476684/: 611= 32.67 gigabytes\n",
            "718706617/: 591= 31.63 gigabytes\n",
            "718987297/: 444= 18.01 gigabytes\n",
            "719458528/: 341= 18.30 gigabytes\n",
            "720463180/: 599= 18.36 gigabytes\n",
            "720948812/: 526= 16.08 gigabytes\n",
            "721065710/: 589= 31.55 gigabytes\n",
            "722033195/: 562= 22.82 gigabytes\n",
            "722603466/: 401= 22.35 gigabytes\n",
            "724316403/: 387= 15.72 gigabytes\n",
            "726555942/: 377= 11.57 gigabytes\n",
            "726635182/: 610= 40.69 gigabytes\n",
            "728203498/: 675= 45.00 gigabytes\n",
            "728251151/: 267= 14.17 gigabytes\n",
            "729522604/: 431= 13.24 gigabytes\n",
            "736979905/: 430= 23.07 gigabytes\n",
            "739291676/: 386= 11.85 gigabytes\n",
            "739383450/: 506= 15.55 gigabytes\n",
            "741428906/: 591= 39.40 gigabytes\n",
            "742421390/: 562= 30.19 gigabytes\n",
            "743214898/: 549= 16.82 gigabytes\n",
            "743274987/: 591= 24.03 gigabytes\n",
            "743918700/: 467= 25.07 gigabytes\n",
            "744609566/: 426= 17.25 gigabytes\n",
            "745145893/: 567= 30.48 gigabytes\n",
            "757721211/: 603= 24.64 gigabytes\n",
            "762275581/: 447= 24.16 gigabytes\n",
            "762912832/: 431= 17.52 gigabytes\n",
            "765078615/: 461= 30.78 gigabytes\n",
            "766985763/: 568= 17.42 gigabytes\n",
            "767485082/: 444= 22.42 gigabytes\n",
            "768977785/: 609= 24.72 gigabytes\n",
            "772239618/: 617= 41.15 gigabytes\n",
            "774495631/: 563= 22.85 gigabytes\n",
            "777467421/: 535= 16.42 gigabytes\n",
            "777472440/: 519= 21.03 gigabytes\n",
            "797376860/: 485= 19.66 gigabytes\n",
            "798631918/: 480= 25.92 gigabytes\n",
            "815877776/: 479= 25.71 gigabytes\n",
            "818150510/: 444= 44.13 gigabytes\n",
            "821560343/: 361= 14.66 gigabytes\n",
            "832210870/: 402= 21.59 gigabytes\n",
            "836350796/: 413= 12.67 gigabytes\n",
            "845142280/: 535= 44.29 gigabytes\n",
            "861519869/: 468= 19.05 gigabytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDp7BKQjoItg",
        "colab_type": "text"
      },
      "source": [
        "106 folders for 105 training neurons and the last folder is `TEST_DATA_SET` which contains 10 neuron image stacks in subfolders (without SWC answers)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na2LMDvToDG9",
        "colab_type": "text"
      },
      "source": [
        "## Trial and error hacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg0FkqTaZlO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import boto3\n",
        "\n",
        "\n",
        "s3 = boto3.resource('s3',\n",
        "     endpoint_url = 'https://s3.us-west-1.wasabisys.com',\n",
        "     aws_access_key_id = '2G7POM6IZKJ3KLHSC4JB',\n",
        "     aws_secret_access_key = '0oHD5BXPim7fR1n7zDXpz4YoB7CHAHAvFgzpuJnt')  \n",
        "  \n",
        "bucket = s3.Bucket('brightfield-auto-reconstruction-competition')\n",
        "#for obj in bucket.objects.filter(Prefix=\"668664690\"):\n",
        "#  print(obj.key)\n",
        "\n",
        "# Good:\n",
        "#print( \"objects=\" + str(sum(1 for _ in bucket.objects.filter(Prefix=\"668664690\"))))\n",
        "\n",
        "  \n",
        "#size = sum(1 for _ in bucket.objects.all())  \n",
        "  \n",
        "  \n",
        "#print ('sub-folders:')  \n",
        "#for obj in bucket.objects.filter(Delimiter=\"/\"):\n",
        "#   print(obj.key)\n",
        "\n",
        "\n",
        "print( \"objects=\" + str(sum(1 for _ in bucket.objects.filter(Delimiter=\"/\"))))\n",
        "\n",
        "  \n",
        "  \n",
        "result = bucket.meta.client.list_objects(Bucket=bucket.name,\n",
        "                                         Delimiter='/')\n",
        "for o in result.get('CommonPrefixes'):\n",
        "    print(o.get('Prefix'))  \n",
        "\n",
        "#list(prefix='/', delimiter='/')\n",
        "\n",
        "# long list of all files\n",
        "#for a_bucket_object in bucket.objects.all():\n",
        "#    print(a_bucket_object.key)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}