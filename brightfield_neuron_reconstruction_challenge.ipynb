{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "brightfield_neuron_reconstruction_challenge.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYqiGtT5kp1q",
        "colab_type": "text"
      },
      "source": [
        "# **The Allen's Brightfield Reconstruction Challenge**\n",
        "\n",
        "<img src=\"http://reconstrue.com/projects/brightfield_neurons/colormapped_turbo.png\" width=\"100%\"/>\n",
        "\n",
        "This code is licensed by Reconstrue under the Apache 2.0 License. Its repo can be found on GitHub, [@reconstrue/brightfield_neuron_reconstruction_on_colab](https://github.com/reconstrue/brightfield_neuron_reconstruction).\n",
        "\n",
        "# <img src=\"http://reconstrue.com/assets/images/reconstrue_logo_brandmark.svg\" width=\"42px\" align=\"top\" /> **Reconstrue**\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "On Colab a notebook's table of contents can be found in the left sidebar, which may be colapsed/hidden (behind an `>` in the upper left corner of the page).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0jGqeD49xXD",
        "colab_type": "text"
      },
      "source": [
        "## TL;dr\n",
        "\n",
        "There's a lot of notebooks and words in this project, and it is all linked to in this main/hub page. If you just want to jump right to the most visually entertaining eye-candy, an example rendering (for dataset specimen `651806289`) is available at [initial_dataset_visualization.specimen_651806289.ipynb](https://colab.research.google.com/drive/1BVoQ1sKxzcpIlDx-TISCLbSadxpETIf6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHFoENqqYV65",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "For [the BioImage Informatics 2019 conference](https://alleninstitute.org/events-training/bioimage-informatics-2019/), the Allen Institute issued a [Brightfield Auto-Reconstruction Challenge](https://alleninstitute.org/events-training/bioimage-informatics-2019/reconstruction-competition/) as a sideshow to the main attraction. The idea was to explore the state of the art of brightfield microscopy neuron reconstruction algorithms. \n",
        "\n",
        "For the challenge, The Allen built out a dataset for use in an evalution competition. The dataset is about 2.5 terabytes in size, consisting of raw brightfield microscopy image stacks produced by The Allen. \n",
        "\n",
        "The dataset also includes SWC files for 105 of the 115 cells. These SWCs contain neuron skeletons manually traced by human experts, the so called gold standards i.e. the best answers as manually labeled (read: neurite tracing) by human beings doing hours of tedious data processing. The challenge is to generate the 10 missing SWCs.\n",
        "\n",
        "<img src=\"http://reconstrue.com/projects/brightfield_neurons/demo_images/651806289_cubehelix.png\" width=\"100%\" alt=\"MinIP(713686035, Turbo)\"/>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCjVCNWt5zcP",
        "colab_type": "text"
      },
      "source": [
        "### Status\n",
        "For full details see [the GitHub projects](https://github.com/reconstrue/brightfield_neuron_reconstruction/projects), especially:\n",
        "- [Colab as main deploy target](https://github.com/reconstrue/brightfield_neuron_reconstruction/projects/1)\n",
        "- [Reconstruction methods\n",
        "](https://github.com/reconstrue/brightfield_neuron_reconstruction/projects/5)\n",
        "\n",
        "Status as of Mon, 2019-11-11:\n",
        "- [x] Overview (this document): sufficiently readable\n",
        "- [x] Dataset exploration:\n",
        "  - On file level, [dataset_manifest.ipynb](https://colab.research.google.com/drive/1_zv9mgrKVCMa5jTnN1CADZFRi3UES6_P#scrollTo=akBdiF6snGGo) \n",
        "  - On image level, [initial_dataset_visualization.ipynb](https://colab.research.google.com/drive/1ZxzDwD1UdYqhuTxckPLiOUYHin0MZmFQ#scrollTo=TaREcuFG6SSQ)\n",
        "- [ ] Method #1: ShuTu reconstruction \n",
        "  - [x] Show working on Colab \n",
        "  - [x] Make SWC from ShuTu's demo data\n",
        "  - [ ] Make SWC form Allen dataset \n",
        "- [ ] Method #2: U-Net reconstruction: only researched\n",
        "  - [ ] CPU deploy \n",
        "  - [ ] GPU deploy\n",
        "- [ ] Summary juxtaposer: not forked out yet but code is ~75% completed\n",
        "- [ ] Judge's Google Form and Google Sheet: not started\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Khc8izE8K7eS",
        "colab_type": "text"
      },
      "source": [
        "### Goals\n",
        "\n",
        "The current goals of this project include:\n",
        "- Explain the Challenge to non-neuroscientist: microscopy and software issues\n",
        "- Perform exploratory data analysis and visualization of the Challenge dataset\n",
        "- Generate SWCs from the Challenge dataset, via the two separate methods submitted to the original 2019-10 Challenge at BioImage 2019\n",
        "- Generate an evaluation notebook juxtaposing SWCs for the 10 test specimen\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3mUuEW46Bh0",
        "colab_type": "text"
      },
      "source": [
        "### Project's Jupyter notebooks\n",
        "This notebook is the main index page for a small collection of other notebooks. This document is just introductory text; the others are software tools. Some of the following notebooks are part of neuro_colab, i.e. not specific to this brightfield work. They are:\n",
        "- Platform basis\n",
        "  - [allensdk_on_colab.ipynb](https://colab.research.google.com/github/JohnTigue/colab-utils/blob/master/tools/allensdk_on_colab.ipynb): AllenSDK install and debug on Colab\n",
        "  - [colab_vm_config_info.ipynb](https://github.com/JohnTigue/colab-utils/blob/master/tools/colab_vm_config_info.ipynb): utils for probing Colab's OS\n",
        "- Dataset exploration\n",
        "  - [dataset_manifest.ipynb](https://colab.research.google.com/drive/1_zv9mgrKVCMa5jTnN1CADZFRi3UES6_P#scrollTo=FQQb1m85EkvC): file level overview of dataset; creates `specimens_manifest.json`\n",
        "  - [initial_dataset_visualization.ipynb](https://colab.research.google.com/drive/1ZxzDwD1UdYqhuTxckPLiOUYHin0MZmFQ#scrollTo=TaREcuFG6SSQ): visual deep dive of a single specimen's imagery; uses `specimens_manifest.json`\n",
        "- Reconstruction method #1: ShuTu\n",
        "  - **TBD:** ShuTu generating SWC for Allen data\n",
        "    - [shutu_makes_swc_for_neuron_651806289.ipynb](https://colab.research.google.com/drive/1CczIvOKomTQexPznDIqb5wErnWJYlBTn#scrollTo=D0T393yXh-a_)\n",
        "    - This is the main ShuTu notebook; the rest are earlier steps\n",
        "  - ShuTu generating SWC for ShuTu demo data\n",
        "    - [brightfield_neuron_swc_by_shutu.ipynb](https://colab.research.google.com/drive/1zdTS1HsAqdH5p4sk42TC6-uFM7f7XUdA#scrollTo=8aBV9zEcLJHm)\n",
        "  - ShuTu installing on Colab\n",
        "    - [install_shutu_on_colab.ipynb](https://colab.research.google.com/drive/1wRnt5ceTs2Oau4g_BiYv09ZOLbv3cyWI#scrollTo=Q1eCY1mvHbCr) \n",
        "  - ShuTu on Colab first test     \n",
        "    - [first_manual_install_of_shutu_on_colab.ipynb](https://colab.research.google.com/drive/1PQEWuFjUi3vo-1btNi6M5vXoNS3dTv5o#scrollTo=qQ5T40Rh0gJk)\n",
        "- Reconstruction method #2: U-Net\n",
        "  - **TBD:** U-Net method: [brightfield_neuron_swc_by_unet_on_colab.ipynb](https://colab.research.google.com/drive/1mbxnqpaU8l17yayCdW-LlYbHb-yXQvqO#scrollTo=TsepXS09_0Qs)\n",
        "- **TBD:** SWC Evalutator: [skeleton_juxtaposer.ipynb](https://colab.research.google.com/drive/1Hj7r49ObIht5YOK6Scz61BxFkFoN76pB#scrollTo=kDsVnYFtIKpa)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O3UG3CDQuTd",
        "colab_type": "text"
      },
      "source": [
        "### Target audience\n",
        "The main goal of this project is to use the Brightfield Challenge dataset as the basis for training models for brightfield neuron skeletonization, which can then be used in production. So, the target audience is two part:\n",
        "- Programmers doing computer vision development (read: training)\n",
        "- Lab scientists wishing to process raw image stacks (read: inference)\n",
        "\n",
        "The primary deployment target for this project is Google Colab, which runs Jupyter notebooks for free. Notebooks are a medium within which both computer programmers and scientist are comfortable. \n",
        "\n",
        "Jupyter notebooks are a popular medium for doing data science. In this project there are two data science users envisioned.\n",
        "1. Computer vision programmer researching object recog \n",
        "2. Folks with a z-stack of brightfield images who want a SWC file.\n",
        "\n",
        "of training object recognition models and/or the data science of wrangling a fresh-off-the-scope image stack into data structures for use by neuroscientists.\n",
        "\n",
        "The platform should enable computer vision programmers to easily innovate on data collected via brightfield microscopy. Additionally, scientists should be able to use\n",
        "\n",
        "a unified research and production.\n",
        "\n",
        "This project processes a single cell's image stack. Demo notebooks show how to generate SWCs, using two completely different methods. One of those two methods is ShuTu. ShuTu also comes with a cross-platform GUI app that enables human editing of generated SWCs. \n",
        "\n",
        "So, there are two imagined audiences\n",
        "1. A sole researcher with a raw image stack off a microscope, no SWC. This person doesn't want to train neural networks, they simply wish to run software that will make an SWC file. This project will walk them all the way from getting files onto Colab where the free T4 GPU can generate SWCs, and finally optionally downloading and editing the generated SWCs client-side. For these folks a full production environment involving nothing but Colab running Jupyter notebooks is provided, with a free open source cross platform desktop app that is a SWC GUI editor for manually cleaning up after the auto reconstruction part is done. Free software, free compute, free (temporary) data storage. Enabling this use case is the intention behind deploying the heavy lifting code to Colab and its free T4 GPU.\n",
        "\n",
        "2. The other audience is computer vision software developers. This project provides Jupyter notebooks that perform basic data triaging, which in the case of microscopy images involves digital photography. These folks will look at the notebook as having done all the unpleasant data wrangling set up. They will hopefully innovate off the full challenge dataset, say using the 105 cells that are already labeled with the training answers (read: SWCs files) as input for training some deep neural network, as is demonstrated in the U-Net method notebooks.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbRmgGUj15To",
        "colab_type": "text"
      },
      "source": [
        "### Brightfield microscopy defined\n",
        "The following image is taken from [the challenge's home page on alleninstitute.org](https://alleninstitute.org/events-training/bioimage-informatics-2019/reconstruction-competition/). It illustrates the objective of this exercise. \n",
        "\n",
        "<img src=\"https://alleninstitute.org/files/resources/1564545471/2651/\" alt=\"(c) Allen Institute\" width=\"100%\"/>\n",
        "\n",
        "In the above image, there are three pairs of images, each pair is vertically aligned, consisting of one grayscale camera image (the input) and one corresponding skeleton (the output) shown as the neon colored lines on a dark field. \n",
        "\n",
        "The grayscale images are actually 2D projections of a 3D stack of images. The projection image is the result of stacking the images atop each other, viewed as if looking down from the top of the image stack. That stack needs to be sifted through to generate a skeleton. In other words, even those three \"simple\" grayscale image are generated projections of the 3D image stack; thery are not raw TIFF files off some scope.\n",
        "\n",
        "\n",
        "This collection of notebooks demonstrate – with live code on Colab – how to: \n",
        "1. Access the dataset\n",
        "2. Process the data to generate SWC skeleton files\n",
        "3. Juxtapose new reconstruction SWCs alongside manual gold standard SWCs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXUqajwjYdN1",
        "colab_type": "text"
      },
      "source": [
        "## Backgrounder\n",
        "\n",
        "The goal of reconstruction is to automate neurite tracing, basically  of stick figure\n",
        "### What is brightfield microscopy\n",
        "\n",
        "\"Brightfield\" (or [bright-field](https://en.wikipedia.org/wiki/Bright-field_microscopy)) is the term of art for the simpliest type of microscope. In the context of the Challenge dataset,a single neuron is pumped full of biocytin to stain it black, while the rest of the brain tissue in the sample a cleared to be rather translucent (see: PubMed for more on [using biocytin to stain and trace neurons](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3368650/)). \n",
        "\n",
        "So, there is some dark/opaque foreground object (in the context of The Allen's challenge specifically, the object of interest is a single biocytin stained neuron. The object of interest is imaged upon some essentially translucent background (or \"field\"). The field is bright (with light shining through) and the foreground is dark, ergo \"brigthfield.\"\n",
        "\n",
        "For a backgrounder, see the 2007 article out of the Max Planck Institute, [Transmitted light brightfield mosaic microscopy for three-dimensional tracing of single neuron morphology](https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-12/issue-06/064029/Transmitted-light-brightfield-mosaic-microscopy-for-three-dimensional-tracing-of/10.1117/1.2815693.full?SSO=1), to see where thing were at a dozen years ago.\n",
        "\n",
        "The data is collected from a slice of brain about 100 micrometers thick. The slice is imaged tile by overlapping tiled. Then the tiles are stitched together to make a single 2D image. The third dimension is created by repeatedly snapping a picture, but with the focal plane of the microscope dropped about 5 micrometers at a step (a microscopes will have an integrated motorized stages upon which a glass slide with specimen is mounted). An artifact of this technique is that the images at the top and the bottom of the stack seem blurry, which is caused by the darkly stained neuron being out of focus.\n",
        "\n",
        "The specifics of how the data in the Challenge dataset is collected can be found in The Allen's documentation, Allen Cell Types Database whitepaper, Cell Morphology And Histology, [CellTypes_Morph_Overview.pdf](http://help.brain-map.org/download/attachments/8323525/CellTypes_Morph_Overview.pdf?version=4&modificationDate=1528310097913&api=v2):\n",
        "\n",
        ">Serial images (63X magnification) through biocytin-filled neurons...\n",
        "\n",
        ">Individual cells were imaged at higher resolution for the purpose of automated and manual reconstruction.\n",
        "Series of 2D images of single neurons were captured with a 63X objective lens (Zeiss Plan APOCHROMAT\n",
        "63X/1.4 oil, 39.69x total magnification, and an n oil-immersion condenser 1.4 NA), using the Tile & Position and\n",
        "Z-stack ZEN 2012 SP2 software modules (Zeiss). The composite 2D tiled images with X-Y effective pixel size\n",
        "of 0.114 micron x 0.114 micron were acquired at an interval of 0.28 µm along the Z-axis. \n",
        "\n",
        "For a quick-and-dirty overview of the actual wet bench rigmarole involved in generating the biocytin stained samples, see the 8 minute vidoe in [Immunostaining of Biocytin-filled and Processed Sections for Neurochemical Markers](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5264554/) (2016). There is also [an 11 minute 2018 video on JoVE](https://www.jove.com/video/58592/biocytin-recovery-3d-reconstructions-filled-hippocampal-ca2), walking through the nitty-gritty wet bench protocol for imaging neurons with biocytin, which demonstrates manual neuron tracing via Neurolucida .\n",
        "\n",
        "**TODO:** some details on how the images in the dataset were generated. They are already stitched seemingly. There should be some mention of tile stitching. ShuTu can; Challenge dataset already did (obvious artifacts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13D0zeM9Sa49",
        "colab_type": "text"
      },
      "source": [
        "### Why is brightfield reconstruction an interesting problem\n",
        "\n",
        "Brightfield neuron reconsturction is an open image processing problem, and a limiting factor for science that is based on brightfield microscopy. \n",
        "\n",
        "Currently, brightfield neuron reconstruction involves manual labor comprising many hours of manually tracing skeletons from the raw brightfield image stacks. \n",
        "\n",
        "Note that brightfield microscopes are the most basic type of microscope, so solving this problem could enable many labs to \"science faster.\"\n",
        "\n",
        "\n",
        "For a backgrounder, check out [Neuronal Morphology Goes Digital: A Research Hub for Cellular and System Neuroscience](https://www.sciencedirect.com/science/article/pii/S0896627313002328) Parekh & Ascoli (2013, in Neuron). Here's an image from that paper illustrating the diversity of neuron morphologies:\n",
        "\n",
        "<img src=\"https://ars.els-cdn.com/content/image/1-s2.0-S0896627313002328-gr1.jpg\" width=\"100%\"/>\n",
        "\n",
        ">The majority of dendritic and axonal morphology reconstructions to date are based on bright-field microscopy (Halavi et al., 2012), due to its broad compatibility with histological staining methods...\n",
        ">Moreover, the ability to enhance the signal intensity by counterstaining renders bright-field microscopy largely unsurpassed for reconstructions of whole axonal arbors up to the very thin (and typically faint) terminals.\n",
        "\n",
        "So, low tech microscopy that produces great results, that could really use a little software help.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USzcZfq0B4pu",
        "colab_type": "text"
      },
      "source": [
        "### Why on Google Colab\n",
        "For this initial deploy of the challenge, the goal is for all software to run on Google Colab. \n",
        "\n",
        "Colab is Google hosting Jupyter notebooks, along with a nice Nvidia GPU, all for free. The GPU is very useful because there is a 12 hour time limit to run code on Colab, so doing it faster is important. Deep neural networks can be GPU accellerated on Colab (e.g., [U-Net GPU accelerated](https://ngc.nvidia.com/catalog/model-scripts/nvidia:unet_industrial_for_tensorflow)).\n",
        "\n",
        "Using Colab to demo brightfield reconstruction requires host NO servers; Google does that. Google sees Google Colab running Python as little different than Google Sheets running custom JavaScript. Hopefully this will prove to be an attractive and easy to get started was of engaging folks with the Brightfield Challenge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvMFoPfbKQoP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Deliverables\n",
        "\n",
        "The main goal is to provide a starter kit for other folks to hack on in order to run their own reconstruction experiments and visualize the results compared to the human traced gold standard SWC files provided in the challenge dataset.\n",
        "\n",
        "As a starting point, this project seeks to recreate/approximate both types of SWC generators from the original challenge. Here though the SWC generating code will run on Colab (so that anyone can run – and hack on –  the experiment themselves for free on Google Colab).\n",
        "\n",
        "Currently this project looks like it can best be banged out as four interlinked Jupyter notebooks:\n",
        "\n",
        "1. This introductory page\n",
        "2. The juxtaposer, a tool for comparing SWC skeletons of a neuron\n",
        "3. A workbook for generating SWCs, via ShuTu\n",
        "4. A workbook for generating SWCs, via U-Net\n",
        "\n",
        "In response to the original BioImage 2019 challenge, there were two skeleton reconstruction methods that were initially evaluated:\n",
        "\n",
        "1. [Dezhe Jin's](https://www.phys.psu.edu/people/dzj2) ShuTu based solution\n",
        "2. [Olga Gliko's](https://alleninstitute.org/what-we-do/brain-science/about/team/staff-profiles/olga-gliko/) U-Net based solution\n",
        "\n",
        "It just makes sense to recreate both methodologies here on Colab.\n",
        "\n",
        "So there are three sub-projects: ShuTu, U-Net, and juxtaposer. \n",
        "\n",
        "Using the three together, pre-rendered SWCs can be quickly visualized, and for the curious there is code to start hacking on to (re)generate new SWCs which can then be evaluated. In other words, the SWCs will be pre-created on Colab for others to later quickly load and compare, but the more patient can recreate the SWCs on Colab themselves (or hopefully start innovating)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip5clQ-i3qH7",
        "colab_type": "text"
      },
      "source": [
        "### Dataset explorer\n",
        "\n",
        "Before actually demostrating reconstruction code, first let's explore the challenge dataset, in a Jupyter notebook, [challenge_dataset.ipynb](https://colab.research.google.com/drive/1_zv9mgrKVCMa5jTnN1CADZFRi3UES6_P#scrollTo=akBdiF6snGGo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Bk_D7jTF1Uq",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "### Demo method #1: ShuTu\n",
        "\n",
        "<img src=\"http://personal.psu.edu/dzj2/ShuTu/ShuTu_cell_char.jpg\" width=\"600px\"/>\n",
        "\n",
        "See the sibling notebook, [ShuTu on Colab](https://colab.research.google.com/drive/1PQEWuFjUi3vo-1btNi6M5vXoNS3dTv5o#scrollTo=qQ5T40Rh0gJk), to see how ShuTu is used to generate SWC files from brightfield image stacks. \n",
        "\n",
        "Status: ShuTu CLI reconstruction code is working on Colab, as of 2019-10-12, with only a bit of finagling required to make it work. \n",
        "\n",
        "ShuTu demo datasets have been see at around 2 GB. Smallest cell in the challenge dataset is ~6 GB. Perhaps ShuTu on Colab can works for at least some cells. Larger might not work as ShuTu distributes work via MPI, but Colab only gives you one core so that doesn't scale on Colab. Rather need GPU solutions to maximize the Colab resources.\n",
        "\n",
        "ShuTu desktop editor is a separate issue; it is desktop software, not web tech. But it is trivial to download a ShuTu generated SWC made on Colab, downloaded to localhost for ShuTu desktop editing, client-side. Nonetheless, a full web-tech solution would be very desirable... at least for viewing, if not full editing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJBUov2BYd4-",
        "colab_type": "text"
      },
      "source": [
        "### Demo method #2: U-Net\n",
        "\n",
        "**[TBD: Not started on at all]**\n",
        "\n",
        "This project's hub issue tracking U-Net, on GitHub, is [#30: U-Net](https://github.com/reconstrue/brightfield_neuron_reconstruction/issues/30).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRjHP7PCFrhp",
        "colab_type": "text"
      },
      "source": [
        "### The brightfield skeleton juxtaposer\n",
        "\n",
        "The \"juxtaposer\" is simply a Jupyter notebook equivalent of the paper-based evalution system used in the original challenge. \n",
        "\n",
        "This has become a stand-along tool, implemented as a separate notebook,\n",
        "[brightfield_skeleton_juxtaposer.ipynb](https://colab.research.google.com/drive/1Hj7r49ObIht5YOK6Scz61BxFkFoN76pB#scrollTo=kDsVnYFtIKpa), which is to be whatever UI can be deployed on Google Colab to juxtapose two SWC skeleton files.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRyDH27Emuvt",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"http://reconstrue.com/projects/brightfield_neurons/colormapped_viridis.png\" width=\"100%\" alt=\"Viridis colormap example\"/>\n"
      ]
    }
  ]
}