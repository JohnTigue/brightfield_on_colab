{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "brightfield_neuron_reconstruction_challenge.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYqiGtT5kp1q",
        "colab_type": "text"
      },
      "source": [
        "# Brightfield neuron reconstruction challenge\n",
        "\n",
        "<img src=\"http://reconstrue.com/projects/brightfield_skeletons/colormapped_turbo.png\" width=\"500px\"/>\n",
        "\n",
        "## Table of Contents\n",
        "- Introduction\n",
        "- Status\n",
        "- List of project's notebooks\n",
        "- Backgrounder\n",
        "- Deliverables\n",
        "  - (TODO: combine Delivs & List o' notebooks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHFoENqqYV65",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "For [the BioImage Informatics 2019 conference](https://alleninstitute.org/events-training/bioimage-informatics-2019/), the Allen Institute issued a [Brightfield Auto-Reconstruction Challenge](https://alleninstitute.org/events-training/bioimage-informatics-2019/reconstruction-competition/) as a sideshow to the main attraction. The idea was to explore the state of the art of brightfield microscopy neuron reconstruction algorithms. \n",
        "\n",
        "For the challenge, The Allen built out a dataset for use in an evalution competition. The dataset is about 2 terabytes in size, consisting of raw brightfield microscopy image stacks produced by The Allen. \n",
        "\n",
        "The dataset also includes SWC files for 105 of the 115 cells. These SWCs contain neuron skeletons manually traced by human experts, the so called gold standards i.e. the best answers as manually labeled (read: neurite tracing) by human beings doing hours of tedious data processing. The challenge is to generate the 10 missing SWCs\n",
        "\n",
        "<img src=\"http://reconstrue.com/projects/brightfield_skeletons/colormapped_viridis.png\" width=\"500px\" alt=\"Viridis colormap example\"/>\n",
        "\n",
        "\n",
        "## Target audience\n",
        "The main goal of this project is to use the Brightfield Challenge dataset as the basis for a platform for brightfield neuron skeletonization, that should encompass both research and production.\n",
        "\n",
        "The platform is Google Colab running Jupyter notebooks. Notebooks are a medium within which both computer programmers and scientist are comfortable. \n",
        "\n",
        "Note books are a popular medium for doing data science. In this project there are two data science users envisioned.\n",
        "1. Computer vision programmer researching object recog \n",
        "2. Folks with a z-stack of brightfield images who want a SWC file.\n",
        "\n",
        "of training object recognition models and/or the data science of wrangling a fresh-off-the-scope image stack into data structures for use by neuroscientists.\n",
        "\n",
        "The platform should enable computer vision programmers to easily innovate on data collected via brightfield microscopy. Additionally, scientists should be able to use\n",
        "\n",
        "a unified research and production.\n",
        "\n",
        "This project processes a single cell's image stack. Demo notebooks show how to generate SWCs, using two completely different methods. One of those two methods is ShuTu. ShuTu also comes with a cross-platform GUI app that enables human editing of generated SWCs. \n",
        "\n",
        "So, there are two imagined audiences\n",
        "1. A sole researcher with a raw image stack off a microscope, no SWC. This person doesn't want to train neural networks, they simply wish to run software that will make an SWC file. This project will walk them all the way from getting files onto Colab where the free T4 GPU can generate SWCs, and finally optionally downloading and editing the generated SWCs client-side. For these folks a full production environment involving nothing but Colab running Jupyter notebooks is provided, with a free open source cross platform desktop app that is a SWC GUI editor for manually cleaning up after the auto reconstruction part is done. Free software, free compute, free (temporary) data storage. Enabling this use case is the intention behind deploying the heavy lifting code to Colab and its free T4 GPU.\n",
        "\n",
        "2. The other audience is computer vision software developers. This project provides Jupyter notebooks that perform basic data triaging, which in the case of microscopy images involves digital photography. These folks will look at the notebook as having done all the unpleasant data wrangling set up. They will hopefully innovate off the full challenge dataset, say using the 105 cells that are already labeled with the training answers (read: SWCs files) as input for training some deep neural network, as is demonstrated in the U-Net method notebooks.  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbRmgGUj15To",
        "colab_type": "text"
      },
      "source": [
        "## Brightfild defined\n",
        "The following image is taken from [the challenge's home page on alleninstitute.org](https://alleninstitute.org/events-training/bioimage-informatics-2019/reconstruction-competition/). It illustrates the objective of this exercise. \n",
        "\n",
        "<img src=\"https://alleninstitute.org/files/resources/1564545471/2651/\" alt=\"(c) Allen Institute\" width=\"500px\"/>\n",
        "\n",
        "In the above image, there are three pairs of images, each pair is vertically aligned, consisting of one grayscale camera image (the input) and one corresponding skeleton (the output) shown as the neon colored lines on a dark field. \n",
        "\n",
        "The grayscale images are actually 2D projections of a 3D stack of images. The projection image is the result of stacking the images atop each other, viewed as if looking down from the top of the image stack. That stack needs to be sifted through to generate a skeleton. In other words, even those three \"simple\" grayscale image are generated projections of the 3D image stack; thery are not raw TIFF files off some scope.\n",
        "\n",
        "\n",
        "This collection of notebooks demonstrate – with live code – how to: \n",
        "1. Access the dataset\n",
        "2. Analyse the data to generate SWC skeleton files\n",
        "3. Juxtapose new reconstruction SWCs alongside manual gold standard SWCs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCjVCNWt5zcP",
        "colab_type": "text"
      },
      "source": [
        "## Status\n",
        "For full details see the GitHub project, [Recreate challenge on Colab\n",
        "](https://github.com/reconstrue/brightfield_neuron_reconstruction/projects/1). \n",
        "\n",
        "The current goal of this project is to\n",
        "- Explain the challenge\n",
        "- Explore the challenge dataset\n",
        "- Generate SWCs from the challenge dataset, two separate ways.\n",
        "- For both methods, generate a summary juxtaposer page of 10 SWCs.\n",
        "\n",
        "Status as of Mon, 2019-10-21:\n",
        "  1. [x] Overview (this document): good enough to start\n",
        "  1. [x] Dataset exploration [challenge_dataset.ipynb](https://colab.research.google.com/drive/1_zv9mgrKVCMa5jTnN1CADZFRi3UES6_P#scrollTo=akBdiF6snGGo): good enough\n",
        "  1. [ ] Method #1 ShuTu reconstruction \n",
        "     - [x] Show working on Colab \n",
        "     - [x] Make SWC from ShuTu's demo data\n",
        "     - [ ] Make SWC form Allen dataset \n",
        "  2. [ ] Method #2 U-Net reconstruction \n",
        "     - [ ] CPU deploy \n",
        "     - [ ] GPU deploy?\n",
        "  4. [ ] Summary juxtaposer: not started at all\n",
        "  5. [ ] Judge's Google Form and Google Sheet\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3mUuEW46Bh0",
        "colab_type": "text"
      },
      "source": [
        "## Related notebooks\n",
        "This notebook is the main index page for a small collection of other notebooks. This document is just introductory text; the others are software tools. They are:\n",
        "- Dataset exploration\n",
        "  - [challenge_dataset.ipynb](https://colab.research.google.com/drive/1_zv9mgrKVCMa5jTnN1CADZFRi3UES6_P#scrollTo=FQQb1m85EkvC): file level overview of whole dataset\n",
        "  - [initial_dataset_visualization.ipynb](https://colab.research.google.com/drive/1ZxzDwD1UdYqhuTxckPLiOUYHin0MZmFQ#scrollTo=TaREcuFG6SSQ): visual deep dive of a single specimen's imagery\n",
        "- ShuTu\n",
        "  - [ ] ShuTu generating SWC for Allen data\n",
        "    - [shutu_makes_swc_for_neuron_651806289.ipynb](https://colab.research.google.com/drive/1CczIvOKomTQexPznDIqb5wErnWJYlBTn#scrollTo=D0T393yXh-a_)\n",
        "    - This is the main ShuTu notebook; the rest are earlier steps\n",
        "  - [x] ShuTu generating SWC for ShuTu demo data\n",
        "    - [brightfield_neuron_swc_by_shutu.ipynb](https://colab.research.google.com/drive/1zdTS1HsAqdH5p4sk42TC6-uFM7f7XUdA#scrollTo=8aBV9zEcLJHm)\n",
        "  - [x] ShuTu installing on Colab\n",
        "    - [install_shutu_on_colab.ipynb](https://colab.research.google.com/drive/1wRnt5ceTs2Oau4g_BiYv09ZOLbv3cyWI#scrollTo=Q1eCY1mvHbCr) \n",
        "  - [x] ShuTu on Colab first test     \n",
        "    - [first_manual_install_of_shutu_on_colab.ipynb](https://colab.research.google.com/drive/1PQEWuFjUi3vo-1btNi6M5vXoNS3dTv5o#scrollTo=qQ5T40Rh0gJk)\n",
        "- SWC Evalutator: [brightfield_skeleton_juxtaposer.ipynb](https://colab.research.google.com/drive/1Hj7r49ObIht5YOK6Scz61BxFkFoN76pB#scrollTo=kDsVnYFtIKpa)\n",
        "- U-Net:\n",
        "  - U-Net method: [brightfield_neuron_swc_by_unet_on_colab.ipynb](https://colab.research.google.com/drive/1mbxnqpaU8l17yayCdW-LlYbHb-yXQvqO#scrollTo=TsepXS09_0Qs)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXUqajwjYdN1",
        "colab_type": "text"
      },
      "source": [
        "## Backgrounder\n",
        "### What is brightfield microscopy\n",
        "\n",
        "\"Brightfield\" is the term of art for old school microscopes wherein some foreground object of interest is stained dark (in the context of The Allen's challenge specifically, the object of interest is a single biocytin stained neurons. The object of interest is imaged upon some essentially translucent background (or \"field\"). The field is bright (with light shining through) and the foreground is dark, ergo \"brigthfield.\"\n",
        "\n",
        "For a backgrounder, see the 2007 article out of the Max Planck Institute, [Transmitted light brightfield mosaic microscopy for three-dimensional tracing of single neuron morphology](https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-12/issue-06/064029/Transmitted-light-brightfield-mosaic-microscopy-for-three-dimensional-tracing-of/10.1117/1.2815693.full?SSO=1), to see where thing were at a dozen years ago.\n",
        "\n",
        "The data is a slice of brain about 100 micrometers thick. A camera passes over the slice and the tiles are stitched together. A stack of images is created by repeatedly snapping a picture, but with the focal plane of the microscope dropped about 5 micrometers at a step.\n",
        "\n",
        "The specifics of how the data is collected can be found in The Allen's documentation, Allen Cell Types Database whitepaper, Cell Morphology And Histology, [CellTypes_Morph_Overview.pdf](http://help.brain-map.org/download/attachments/8323525/CellTypes_Morph_Overview.pdf?version=4&modificationDate=1528310097913&api=v2):\n",
        "\n",
        ">Serial images (63X magnification) through biocytin-filled neurons...\n",
        "\n",
        ">Individual cells were imaged at higher resolution for the purpose of automated and manual reconstruction.\n",
        "Series of 2D images of single neurons were captured with a 63X objective lens (Zeiss Plan APOCHROMAT\n",
        "63X/1.4 oil, 39.69x total magnification, and an n oil-immersion condenser 1.4 NA), using the Tile & Position and\n",
        "Z-stack ZEN 2012 SP2 software modules (Zeiss). The composite 2D tiled images with X-Y effective pixel size\n",
        "of 0.114 micron x 0.114 micron were acquired at an interval of 0.28 µm along the Z-axis. \n",
        "\n",
        "For a quick-and-dirty overview of the actual wet bench rigmarole involved in generating the biocytin stained samples, see the 8 minute vidoe in [Immunostaining of Biocytin-filled and Processed Sections for Neurochemical Markers](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5264554/) (2016)\n",
        "\n",
        "### Why is brightfield reconstruction an interesting problem\n",
        "\n",
        "Brightfield neuron reconsturction is an open image processing problem, and a limiting factor for science that is based on brightfield microscopy. \n",
        "\n",
        "Currently, brightfield neuron reconstruction involves manual labor comprising many hours of manually tracing skeletons from the raw brightfield image stacks. \n",
        "\n",
        "Note that brightfield microscopes are the most basic type of microscope, so solving this problem could enable many labs to \"science faster.\"\n",
        "\n",
        "\n",
        "For a backgrounder, check out [Neuronal Morphology Goes Digital: A Research Hub for Cellular and System Neuroscience](https://www.sciencedirect.com/science/article/pii/S0896627313002328) Parekh & Ascoli (2013, in Neuron). Here's an image from that paper:\n",
        "\n",
        "<img src=\"https://ars.els-cdn.com/content/image/1-s2.0-S0896627313002328-gr1.jpg\" width=\"600px\"/>\n",
        "\n",
        ">The majority of dendritic and axonal morphology reconstructions to date are based on bright-field microscopy (Halavi et al., 2012), due to its broad compatibility with histological staining methods...\n",
        ">Moreover, the ability to enhance the signal intensity by counterstaining renders bright-field microscopy largely unsurpassed for reconstructions of whole axonal arbors up to the very thin (and typically faint) terminals.\n",
        "\n",
        "So, low tech microscopy that produces great results, that could really use a little software help.\n",
        "\n",
        "### Why on Google Colab\n",
        "Colab is basically just Google hosting Jupyter notebooks for free, with a nice GPU as a bonus. The GPU is very useful because there is a 12 time limit to run code on Colab, so doing it faster is important.\n",
        "\n",
        "Deep neural networks can be GPU accellerated on Colab (e.g., [a YOLO net trained on Colab's GPU](https://dev.to/kriyeng/8-tips-for-google-colab-notebooks-to-take-advantage-of-their-free-of-charge-12gb-ram-gpu-be4)).\n",
        "\n",
        "Using Colab to demo brightfield reconstruction requires host NO servers, Google does that. Google sees Jupyter as a Python equivalent to Google Sheets running custom JavaScript.\n",
        "\n",
        "For this initial deploy of the challenge, the goal is for all software to run on Google Colab. After getting things working on Colab, subsequently getting JupyterLab running on Binder (Docker) is much simpler, trivial usually. So, if someone wants to experiment on their own hardware, the Binder deploy (**TBD**) is a great starting point.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvMFoPfbKQoP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Deliverables\n",
        "\n",
        "The main goal is to provide a starter kit for other folks to hack on in order to run their own reconstruction experiments and visualize the results compared to the human traced gold standard SWC files provided in the challenge dataset.\n",
        "\n",
        "As a starting point, this project seeks to recreate/approximate both types of SWC generators from the original challenge. Here though the SWC generating code will run on Colab (so that anyone can run – and hack on –  the experiment themselves for free on Google Colab).\n",
        "\n",
        "Currently this project looks like it can best be banged out as four interlinked Jupyter notebooks:\n",
        "\n",
        "1. This introductory page\n",
        "2. The juxtaposer, a tool for comparing SWC skeletons of a neuron\n",
        "3. A workbook for generating SWCs, via ShuTu\n",
        "4. A workbook for generating SWCs, via U-Net\n",
        "\n",
        "In response to the original BioImage 2019 challenge, there were two skeleton reconstruction methods that were initially evaluated:\n",
        "\n",
        "1. [Dezhe Jin's](https://www.phys.psu.edu/people/dzj2) ShuTu based solution\n",
        "2. [Olga Gliko's](https://alleninstitute.org/what-we-do/brain-science/about/team/staff-profiles/olga-gliko/) U-Net based solution\n",
        "\n",
        "It just makes sense to recreate both methodologies here on Colab.\n",
        "\n",
        "So there are three sub-projects: ShuTu, U-Net, and juxtaposer. \n",
        "\n",
        "Using the three together, pre-rendered SWCs can be quickly visualized, and for the curious there is code to start hacking on to (re)generate new SWCs which can then be evaluated. In other words, the SWCs will be pre-created on Colab for others to later quickly load and compare, but the more patient can recreate the SWCs on Colab themselves (or hopefully start innovating)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip5clQ-i3qH7",
        "colab_type": "text"
      },
      "source": [
        "### Dataset explorer\n",
        "\n",
        "Before actually demostrating reconstruction code, first let's explore the challenge dataset, in a Jupyter notebook, [challenge_dataset.ipynb](https://colab.research.google.com/drive/1_zv9mgrKVCMa5jTnN1CADZFRi3UES6_P#scrollTo=akBdiF6snGGo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Bk_D7jTF1Uq",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "### Demo method #1: ShuTu\n",
        "\n",
        "<img src=\"http://personal.psu.edu/dzj2/ShuTu/ShuTu_cell_char.jpg\" width=\"600px\"/>\n",
        "\n",
        "See the sibling notebook, [ShuTu on Colab](https://colab.research.google.com/drive/1PQEWuFjUi3vo-1btNi6M5vXoNS3dTv5o#scrollTo=qQ5T40Rh0gJk), to see how ShuTu is used to generate SWC files from brightfield image stacks. \n",
        "\n",
        "Status: ShuTu CLI reconstruction code is working on Colab, as of 2019-10-12, with only a bit of finagling required to make it work. \n",
        "\n",
        "ShuTu desktop editor is a separate issue; it is desktop software, not web tech. But it is trivial to download a ShuTu generated SWC made on Colab, downloaded to localhost for ShuTu desktop editing, client-side. Nonetheless, a full web-tech solution would be very desirable... at least for viewing, if not full editing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJBUov2BYd4-",
        "colab_type": "text"
      },
      "source": [
        "### Demo method #2: U-Net\n",
        "\n",
        "**[TBD: Not started on at all]**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRjHP7PCFrhp",
        "colab_type": "text"
      },
      "source": [
        "### The brightfield skeleton juxtaposer\n",
        "\n",
        "The \"juxtaposer\" is simply a Jupyter notebook equivalent of the paper-based evalution system used in the original challenge. \n",
        "\n",
        "This has become a stand-along tool, implemented as a separate notebook,\n",
        "[brightfield_skeleton_juxtaposer.ipynb](https://colab.research.google.com/drive/1Hj7r49ObIht5YOK6Scz61BxFkFoN76pB#scrollTo=kDsVnYFtIKpa), which is to be whatever UI can be deployed on Google Colab to juxtapose two SWC skeleton files.\n",
        "\n",
        "\n"
      ]
    }
  ]
}